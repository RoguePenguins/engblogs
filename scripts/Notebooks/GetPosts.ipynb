{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d210096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Introducing English as the New Programming Language for Apache Spark', 'title_detail': {'type': 'text/plain', 'language': None, 'base': 'https://www.databricks.com/blog/category/engineering/feed.xml', 'value': 'Introducing English as the New Programming Language for Apache Spark'}, 'published': 'Thu, 29 Jun 2023 09:12:01 GMT', 'published_parsed': time.struct_time(tm_year=2023, tm_mon=6, tm_mday=29, tm_hour=9, tm_min=12, tm_sec=1, tm_wday=3, tm_yday=180, tm_isdst=0), 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.databricks.com/blog/introducing-english-new-programming-language-apache-spark'}], 'link': 'https://www.databricks.com/blog/introducing-english-new-programming-language-apache-spark', 'summary': '<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">Introduction We are thrilled to unveil the English SDK for Apache Spark, a transformative tool designed to enrich your Spark experience. Apache Spark™...</div>', 'summary_detail': {'type': 'text/html', 'language': None, 'base': 'https://www.databricks.com/blog/category/engineering/feed.xml', 'value': '<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">Introduction We are thrilled to unveil the English SDK for Apache Spark, a transformative tool designed to enrich your Spark experience. Apache Spark™...</div>'}, 'tags': [{'term': 'Open Source', 'scheme': None, 'label': None}], 'content': [{'type': 'text/html', 'language': None, 'base': 'https://www.databricks.com/blog/category/engineering/feed.xml', 'value': '<div class=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\">Introduction We are thrilled to unveil the English SDK for Apache Spark, a transformative tool designed to enrich your Spark experience. Apache Spark™...</div>'}], 'id': 'https://www.databricks.com/node/6583', 'guidislink': False}\n",
      "Created post for Introducing English as the New Programming Language for Apache Spark - https://www.databricks.com/blog/introducing-english-new-programming-language-apache-spark\n",
      "Full text of Introducing English as the New Programming Language for Apache Spark: Discover how to build and manage all your data, analytics and AI use cases with the Databricks Lakehouse Platform Report\n",
      "\n",
      "Tap the potential of AI\n",
      "Explore recent findings from 600 CIOs across 14 industries in this MIT Technology Review report Missed Data + AI Summit?   Data + AI Summit is over, but you can still watch the keynotes and 250+ sessions from the event on demand. Connect with validated partner solutions in just a few clicks. See why Gartner named Databricks a Leader for the second consecutive year June 29, 2023 in Open Source We are thrilled to unveil the English SDK for Apache Spark, a transformative tool designed to enrich your Spark experience. Apache Spark™, celebrated globally with over a billion annual downloads from 208 countries and regions, has significantly advanced large-scale data analytics. With the innovative application of Generative AI, our English SDK seeks to expand this vibrant community by making Spark more user-friendly and approachable than ever! GitHub Copilot has revolutionized the field of AI-assisted code development. While it's powerful, it expects the users to understand the generated code to commit. The reviewers need to understand the code as well to review. This could be a limiting factor for its broader adoption. It also occasionally struggles with context, especially when dealing with Spark tables and DataFrames. The attached GIF illustrates this point, with Copilot proposing a window specification and referencing a non-existent 'dept_id' column, which requires some expertise to comprehend. \n",
      "Instead of treating AI as the copilot, shall we make AI the chauffeur and we take the luxury backseat? This is where the English SDK comes in. We find that the state-of-the-art large language models know Spark really well, thanks to the great Spark community, who over the past ten years contributed tons of open and high-quality content like API documentation, open source projects, questions and answers, tutorials and books, etc. Now we bake Generative AI’s expert knowledge about Spark into the English SDK. Instead of having to understand the complex generated code, you could get the result with a simple instruction in English that many understand: The English SDK, with its understanding of Spark tables and DataFrames, handles the complexity, returning a DataFrame directly and correctly! Our journey began with the vision of using English as a programming language, with Generative AI compiling these English instructions into PySpark and SQL code. This innovative approach is designed to lower the barriers to programming and simplify the learning curve. This vision is the driving force behind the English SDK and our goal is to broaden the reach of Spark, making this very successful project even more successful.  The English SDK simplifies Spark development process by offering the following key features: To illustrate how the English SDK can be used, let's look at a few examples: Data Ingestion\n",
      "If you're a data scientist who needs to ingest 2022 USA national auto sales, you can do this with just two lines of code: DataFrame Operations\n",
      "Given a DataFrame df, the SDK allows you to run methods starting with df.ai. This includes transformations, plotting, DataFrame explanation, and so on.\n",
      "To active partial functions for PySpark DataFrame: To take an overview of `auto_df`:  To view the market share distribution across automotive companies:  To get the brand with the highest growth: us_sales_2022 Cadillac 134726 To get the explanation of a DataFrame: In summary, this DataFrame is retrieving the brand with the highest sales change in 2022 compared to 2021. It presents the results sorted by sales change in descending order and only returns the top result. User-Defined Functions (UDFs)\n",
      "The SDK supports a simple and neat UDF creation process. With the @spark_ai.udf decorator, you only need to declare a function with a docstring, and the SDK will automatically generate the code behind the scene: Now you can use the UDF in SQL queries or DataFrames The English SDK for Apache Spark is an extremely simple yet powerful tool that can significantly enhance your development process. It's designed to simplify complex tasks, reduce the amount of code required, and allow you to focus more on deriving insights from your data. While the English SDK is in the early stages of development, we're very excited about its potential. We encourage you to explore this innovative tool, experience the benefits firsthand, and consider contributing to the project. Don't just observe the revolution—be a part of it. Explore and harness the power of the English SDK at pyspark.ai today. Your insights and participation will be invaluable in refining the English SDK and expanding the accessibility of Apache Spark. See Careers\n",
      "at Databricks Databricks Inc.\n",
      "160 Spear Street, 13th Floor\n",
      "San Francisco, CA 94105\n",
      "1-866-330-0121 © Databricks 2023. All rights reserved. Apache, Apache Spark, Spark and the Spark logo are trademarks of the Apache Software Foundation.\n",
      "\n",
      "Created post for Announcing Delta Lake 3.0 with New Universal Format and Liquid Clustering - https://www.databricks.com/blog/announcing-delta-lake-30-new-universal-format-and-liquid-clustering\n",
      "Full text of Announcing Delta Lake 3.0 with New Universal Format and Liquid Clustering: Discover how to build and manage all your data, analytics and AI use cases with the Databricks Lakehouse Platform Report\n",
      "\n",
      "Tap the potential of AI\n",
      "Explore recent findings from 600 CIOs across 14 industries in this MIT Technology Review report Missed Data + AI Summit?   Data + AI Summit is over, but you can still watch the keynotes and 250+ sessions from the event on demand. Connect with validated partner solutions in just a few clicks. See why Gartner named Databricks a Leader for the second consecutive year June 29, 2023 in Engineering Blog We are excited to announce Delta Lake 3.0, the next major release of the Linux Foundation open source Delta Lake Project, available in preview now. We extend our sincere appreciation to the Delta Lake community for their invaluable contributions to this release. Delta Lake 3.0 introduces the following powerful features: In this blog, we’re going to dive into the details of the Delta Lake 3.0 capabilities, through the lens of customer challenges that they solve.   Challenge #1: I like the idea of a data lakehouse but which storage format should I choose? Companies are interested in combining their data warehouses and data lakes into an open data lakehouse. This move avoids locking data into proprietary formats, and it enables using the right tool for the right job against a single copy of data. However, they struggle with the decision of whether to standardize on a single open lakehouse format and which one to use. They may have a number of existing data warehouses and data lakes being used by different teams, each with its own preferred data connectors. Customers are concerned that picking a single storage format will lead to its own form of lock-in, and they worry about going through one-way doors. Migration is costly and difficult, so they want to make the right decision up front and only have to do it once. They ultimately want the best performance at the cheapest price for all of their data workloads including ETL, BI, and AI, and the flexibility to consume that data anywhere. Solution: Delta UniForm automatically and instantly translates Delta Lake to Iceberg and Hudi. Delta Universal Format (UniForm) automatically unifies table formats, without creating additional copies of data or more data silos. Teams that use query engines designed to work with Iceberg or Hudi data will be able to read Delta tables seamlessly, without having to copy data over or convert it. Customers don’t have to choose a single format, because tables written by Delta will be universally accessible by Iceberg and Hudi readers.  UniForm takes advantage of the fact that all three open lakehouse formats are thin layers of metadata atop Parquet data files. As writes are made, UniForm will incrementally generate this layer of metadata to spec for Hudi, Iceberg and Delta.  In benchmarking, we’ve seen that UniForm introduces negligible performance and resource overhead. We also saw improved read performance on UniForm-enabled tables relative to native Iceberg tables, thanks to Delta’s improved data layout capabilities like Z-order. With UniForm, customers can choose Delta with confidence, knowing that by choosing Delta, they’ll have broad support from any tool that supports lakehouse formats. “Collaboration and innovation in the financial services industry are fueled by the open source community and projects like Legend, Goldman Sachs’ open source data platform that we maintain in partnership with FINOS,” said Neema Raphael, Chief Data Officer and Head of Data Engineering at Goldman Sachs. “We’ve long believed in the importance of open source to technology’s future and are thrilled to see Databricks continue to invest in Delta Lake. Organizations shouldn’t be limited by their choice of an open table format and Universal Format support in Delta Lake will continue to move the entire community forward.”   Challenge #2: Figuring out the right partitioning keys for optimal performance is a Goldilocks Problem When building a data lakehouse, it’s hard to come up with a one-size-fits-all partitioning strategy that not only fits the current data query patterns but also adapts to the new workloads over time. Because of the fixed data layout, choosing the right partitioning strategy means teams have to put a lot of careful thought and planning upfront into the partitioning strategy. And despite best efforts, with time, query patterns change, and the initial partitioning strategy becomes inefficient and expensive. Features such as Partition Evolution are somewhat useful in making Hive-style partitioning more flexible but it requires table owners to continuously monitor their tables and “evolve” the partitioning columns. All of these steps add engineering work and are not easy to do for a large segment of users who just want to get insights from their data. And despite best efforts, the distribution of data across partitions can become uneven over time directly impacting read/write performance. Solution: Liquid's flexible data layout technique can self-tune to fit your data now and as it grows. Liquid Clustering is a smart data management technique for Delta tables. It is flexible and automatically adjusts the data layout based on clustering keys. Liquid Clustering dynamically clusters data based on data patterns, which helps to avoid the over- or under-partitioning problems that can occur with Hive partitioning.  To test the performance of Liquid, we ran a benchmark of a typical 1 TB data warehouse workload. Liquid Clustering resulted in 2.5x faster clustering relative to Z-order. In the same trial, traditional Hive-style partitioning was an order of magnitude slower due to the expensive shuffle required for writing out many partitions. Liquid also incrementally clusters new data as it is ingested, paving the way for consistently fast read performance.   Challenge #3: Deciding which connector to prioritize is tricky for integrators. The connector ecosystem for Delta is large and growing to meet the rapid adoption of the format. As engine integrators and developers build connectors for open source storage formats, they have a decision to make about which format to prioritize first. They have to balance the maintenance time and costs against engineering resources because every new protocol specification requires new code. Solution: Kernel unifies the connector ecosystem. Delta Kernel is a new initiative that will provide simplified, narrow and stable programmatic APIs that hide all the complex Delta protocol details. With Kernel, connector developers will have access to all new Delta features by updating the Kernel version itself, not a single line of code. For end users, this means faster access to the latest Delta innovations across the ecosystem. Together with UniForm, Kernel further unifies the connector ecosystem, because Delta will write out metadata for Iceberg and Hudi automatically. For engine integrators, this means that when you build once for Delta, you build for everyone.  The preview release candidate for Delta Lake 3.0 is available today. Databricks customers can also preview these features in Delta Lake with DBR version 13.2 or the next preview channel of DBSQL coming soon.   Interested in participating in the open source Delta Lake community? Visit Delta Lake to learn more; you can join the Delta Lake community via Slack and Google Group. If you’re interested in contributing to the project, see the list of open issues here. A big thank you to the following contributors for making this release available to the community: Ahir Reddy, Ala Luszczak, Alex, Allen Reese, Allison Portis, Antoine Amend, Bart Samwel, Boyang Jerry Peng, CabbageCollector, Carmen Kwan, Christos Stavrakakis, Denny Lee, Desmond Cheong, Eric Ogren, Felipe Pessoto, Fred Liu, Fredrik Klauss, Gerhard Brueckl, Gopi Krishna Madabhushi, Grzegorz Kołakowski, Herivelton Andreassa, Jackie Zhang, Jiaheng Tang, Johan Lasperas, Junyong Lee, K.I. (Dennis) Jung, Kam Cheung Ting, Krzysztof Chmielewski, Lars Kroll, Lin Ma, Luca Menichetti, Lukas Rupprecht, Ming DAI, Mohamed Zait, Ole Sasse, Olivier Nouguier, Pablo Flores, Paddy Xu, Patrick Pichler, Paweł Kubit, Prakhar Jain, Ryan Johnson, Sabir Akhadov, Satya Valluri, Scott Sandre, Shixiong Zhu, Siying Dong, Son, Tathagata Das, Terry Kim, Tom van Bussel, Venki Korukanti, Wenchen Fan, Yann Byron, Yaohua Zhao, Yuhong Chen, Yuming Wang, Yuya Ebihara, aokolnychyi, gurunath, jintao shen, maryannxue, noelo, panbingkun, windpiger, wwang-talend See Careers\n",
      "at Databricks Databricks Inc.\n",
      "160 Spear Street, 13th Floor\n",
      "San Francisco, CA 94105\n",
      "1-866-330-0121 © Databricks 2023. All rights reserved. Apache, Apache Spark, Spark and the Spark logo are trademarks of the Apache Software Foundation.\n",
      "\n",
      "Created post for Project Lightspeed Update - Advancing Apache Spark Structured Streaming - https://www.databricks.com/blog/project-lightspeed-update-advancing-apache-spark-structured-streaming\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full text of Project Lightspeed Update - Advancing Apache Spark Structured Streaming: Discover how to build and manage all your data, analytics and AI use cases with the Databricks Lakehouse Platform Report\n",
      "\n",
      "Tap the potential of AI\n",
      "Explore recent findings from 600 CIOs across 14 industries in this MIT Technology Review report Missed Data + AI Summit?   Data + AI Summit is over, but you can still watch the keynotes and 250+ sessions from the event on demand. Connect with validated partner solutions in just a few clicks. See why Gartner named Databricks a Leader for the second consecutive year June 29, 2023 in Engineering Blog In this blog post, we will review the advancements in Spark Structured Streaming since we announced Project Lightspeed a year ago, from performance improvements to ecosystem expansion and beyond. Before we discuss specific innovations, let’s review a bit of background on how we arrived at the need for Project Lightspeed in the first place. Stream processing is a critical need for the enterprise to get instant insights and real time feedback. Apache Spark Structured Streaming has been the most popular open-source streaming engine for years because of its ease of use, performance, large ecosystem, and developer communities. It is widely adopted across organizations in open source and is the core technology that powers streaming on Delta Live Tables (DLT) and the Databricks Lakehouse Platform.  Our customers are doing amazing things with streaming data, at record-setting price and performance: In fact, the Databricks Lakehouse Platform is trusted by thousands of customers for streaming data workloads that empower real-time analytics, real-time AI and ML, and real-time applications. There are over 10 million Streaming jobs run per week on Databricks, a number that is still growing at more than 2.5x every year. These jobs are processing multiple petabytes of data (compressed) per day.  At the 2022 Data+AI Summit, we announced Project Lightspeed, an initiative dedicated to faster and simpler stream processing with Apache Spark. Lightspeed represents a concerted investment in Spark as the streaming engine of the future, and the Databricks Lakehouse Platform as the best place to run Spark workloads - as well as an acknowledgement of streaming data architectures as the inevitable future of all data. Project Lightspeed has brought in advancements to Structured Streaming in four distinct buckets. All of these are aimed to make Apache Spark Structured Streaming and the Databricks Runtime increasingly better at handling complex real-time data workloads. Here is a summary of what’s new in Project Lightspeed over the last year, divided by bucket: I. Improvements in performance and providing consistent latency II. Enhanced functionality for processing data III. Improvements in observability and troubleshooting IV. Ecosystem expansion with new connectors Offset Management Support for Multiple Stateful Operators Python Query Listener Enhanced Fanout (EFO) Support for Amazon Kinesis Log Purging Arbitrary Stateful Processing in Python Google Pub/Sub Connector Microbatch Pipelining Drop Duplicates Within Watermark Performance Considerations for Stateful Pipelines Support Protobuf serialization natively State Rebalancing Adaptive Query Execution In this post, we will explore all the changes brought by Project Lightspeed so far. We'll cover everything from the new latency improvements to improved connectors for popular messaging systems like Amazon Kinesis and Google Pub/Sub.  While Spark's design enables high throughput and ease-of-use at a lower cost, it had not been optimized for sub-second latency. We implemented several techniques and features to achieve consistent, sub-second latency. These improvements are as follows. Apache Spark Structured Streaming relies on persisting and managing offsets to track the progress of up to which point the data has been processed. This translates into two book keeping operations for each micro-batch.  Previously, both these operations were performed on the critical path of data processing and significantly impacted processing latency and cluster utilization. To address this overhead of persisting offsets, we implemented asynchronous progress tracking in Project Lightspeed. This implementation allows Structured Streaming pipelines to update the logs asynchronously and in parallel to the actual data processing within a micro-batch. Performance experiments show a consistent reduction of as much as 3X from 700-900 ms to 150-250 ms in latency for throughputs of 100K, 500K and 1M events/sec. Availability - This feature has been available from DBR 11.3 and subsequent releases. For more details, read the blog - Latency goes subsecond in Apache Spark Structured Streaming. In addition to the offset management for progress tracking, previously Structured Streaming ran a cleanup operation at the end of every micro-batch. This operation deletes or truncates the old and unnecessary log entries of progress tracking so that these logs do not accumulate and grow in an unbounded fashion. This operation was performed inline with the actual processing of data that impacts latency. To remove this overhead, the log cleanups were made asynchronous in Project Lightspeed and performed in the background in a relaxed schedule thus reducing the latency of every micro-batch. This improvement applies to all pipelines and workloads and hence enabled in the background by default for all Structured Streaming pipelines. Our performance evaluation indicates that it reduces latency by 200-300 ms for throughputs of 100K, 500K and 1M events/sec. Availability - This feature has been available from DBR 11.3 and subsequent releases. For more details, read the blog - Latency goes subsecond in Apache Spark Structured Streaming. When running Structured Streaming queries for benchmarking, we observed lower utilization of spark clusters, higher latency and lower throughput. On further investigation, we realized it is due to the underlying execution mechanism in Structured Streaming which is as follows: Because of this, a single task of the current micro-batch that is taking longer to finish will delay the scheduling of the execution of the tasks of the next micro-batch. During this time, the task slots of the tasks that have already been completed are not utilized, which leads to higher latency and lower throughput.  In order to improve utilization and lower the latency, we modified the execution mechanism so that the tasks of the next micro-batch are started immediately after “each” task of the previous micro-batch completes rather than waiting for “all” the tasks of the previous micro-batch to finish. Essentially, we pipeline the execution of micro-batches or execute many micro-batches concurrently.   In the benchmarks we have run so far to quantify the performance uplift pipelined execution gives, we have noticed a 2-3x improvement in throughput and cost reduction. We intend to run more benchmarks and further optimize the performance improvement pipelined execution can offer. Availability - This feature will be GAed in Q3 of 2023. In the existing model, when Structured Streaming pipelines used RocksDB state store provider, we used to observe higher and variable latency. During a detailed investigation, we identified that commit operations related to the state store contributed to 50-80% of task duration and also accounted for the high, variable latency. Here are some of the issues that we have seen: To address the issues discussed above, we have made a number of improvements to achieve faster and consistent performance. Availability - All the above improvements will be available from DBR 13.2 and subsequent releases. In Structured Streaming, some operators are stateful (e.g. mapGroupsWithState). For distributed execution, the state of these operators are sharded into partitions and saved in between microbatch executions on the local executor disk and also checkpointed to the distributed file system. Typically, one spark execution task is usually associated with managing one state partition. Currently, by default, the stateful operators are sharded into 200 partitions.  The tasks associated with each partition are executed for the first time on the executors picked randomly based on the availability of idle resources for them. In subsequent micro-batch executions, the task scheduler will prefer to schedule the state partition tasks on the same executors which executed them previously (unless the executor died or the stateful tasks are waiting for execution above a certain threshold and get picked by some other idle executor). This is to take advantage of the locality of state cached in memory or in local disk. Such a behavior poses a problem especially when new executors are added to the cluster (due to autoscaling), the state task may continue to execute on their original executors and not utilize the new resources provided. Thus, scaling the cluster up will not spread the execution of stateful tasks optimally. In order to efficiently utilize the resources, we implemented a state rebalancing algorithm in the task scheduler that ensures the tasks associated with the state are evenly spread across the available executors when new executors are added or removed - even if it involves loading the state in a new executor from a distributed file system. The rebalancing algorithm ensures there is no state placement flapping as it will converge with minimal number of movement of state tasks for an optimal placement. Subsequent optimality recomputation will not result in movements of the state tasks, assuming no changes in the set of executors or the partition count. Availability - This feature has been available from DBR 11.1 and subsequent releases. More than 40% of Databricks Structured Streaming customers use the ForeachBatch sink. Usually, it is used for resource intensive operations such as joins and Delta Merge with large volumes of data. This resulted in multi-staged execution plans that relied on static query planning and estimated statistics that led to poor physical execution strategies and reduced performance in the case of skewed data distributions. To address these challenges, we use the runtime statistics collected during the previous micro-batch executions of the ForeachBatch sink to optimize subsequent micro-batches. Adaptive query replanning is triggered independently for each micro-batch because the characteristics of the data might potentially change over time across different micro-batches. Our performance experiments on stateless queries bottlenecked by expensive joins and aggregations experienced a speedup ranging from 1.2x to 2x. Availability - This feature has been available from DBR 13.1 and subsequent releases. For more details, read the blog - Adaptive Query Execution in Structured Streaming. As enterprises expand the use of streaming for more use cases, they are requesting more functionality to express the logic more concisely and natively. Accordingly, we have incorporated the following functionality, continuing to add even more today. Previously, support for multiple stateful operators within a streaming query in Structured Streaming was lacking. For example, a streaming query with two windowed aggregations was not supported and would not run correctly. While there are workarounds to get around these limitations, such as decomposing the query into separate queries connected by external storage, these have drawbacks from a user experience, system performance, and cost of operations perspective.. Because of this, there are many potential use cases involving multiple stateful operators in a single query that are difficult to implement in Structured Streaming.  The reason multiple stateful operators cannot be supported was due to several underlying issues with how the previous watermarking mechanism worked. Among them are broken late record filtering and inadequate event time column tracking, but, most importantly, support for tracking watermarks on a per stateful operator basis was missing. Previously, only a single “global” watermark value was tracked per streaming query. Due to this, multiple stateful operators could not be supported since one watermark is not adequate to track the execution progress of more than one stateful operator. These limitations have been fixed and watermarks are now tracked for each stateful operator allowing streaming queries with multiple stateful operators to execute correctly. Availability - This feature has been available from DBR 13.1 and subsequent releases. One primary use case for stream processing is performing continuous aggregation over input data. For example, in options trading we need to provide the capability to the user to write their own exponential weighted moving average. Structured Streaming provides arbitrary stateful operations with flatMapGroupsWithState() and mapGroupsWithState()to address such use cases. However, this functionality was not available in PySpark so far. This leads to users switching to Scala or Java and preventing them from working with popular Python libraries like Pandas.  We closed this gap in PySpark by adding support for arbitrary stateful operation in Structured Streaming. We introduced a new API DataFrame.groupby.applyInPandasWithState that allows the users to invoke their own function that updates the state. Availability - This feature has been available from DBR 11.3 onwards. For more details, read the blog - Python Arbitrary Stateful Processing in Structured Streaming. Previously, a timestamp column that contains the event time information for the row must be passed into thedropDuplicates function in order to compute the watermark that determines what state information can be cleaned up. This event time column is also considered when determining whether a row is a duplicate or not. This is often not the behavior the user wants as the user typically wants to take into account the columns other than the event time column in the deduplication process. This issue creates confusion among users on how to use this function properly. This issue was solved by creating a new function dropDuplicatesWithinWatermark that allows users to declare the event time column used for watermarking separately of the columns that the users want to consider for deduplication purposes. Native support for Protocol Buffers (Protobuf) in Structured Streaming. With this enhancement customers can serialize and deserialize Protobuf data using Spark data transformers. Spark now exposes two functionsfrom_protobuf() and to_protobuf(). The function from_protobuf() casts a binary column to a struct whileto_protobuf() casts a struct column to binary. Availability - This feature has been available from DBR 13.0 onwards. For more details see the documentation. Since streaming jobs run continuously, it is important to have metrics and tools for monitoring, debugging and alerting in production scenarios. In order to improve observability, we added the following features. Structured Streaming addresses the problem of monitoring streaming workloads by providing: The Observable API has been missing in PySpark, which forces users to use the Scala API for their streaming queries. The lack of this functionality in Python has become more critical as the importance of Python grows, given that almost 70% of notebook commands run on Databricks are in Python. We implemented the Observable API with a streaming query listener in PySpark that allows the developers to send streaming metrics to external systems. The Streaming Query Listener is an abstract class that has to be inherited and should implement all methods, onQueryStarted, onQueryProgress, and onQueryTerminated. Availability - This feature has been available from DBR 11.0 onwards. For more details, read the blog - How to Monitor Streaming Queries in PySpark. As cloud providers provide many sources and sinks for data, we need to make it easier for Structured Streaming to read from them and write the processed data to them, essentially expanding the ecosystem of connectors. In this aspect, we enhanced existing connectors and added new connectors that are expanded below. Amazon Kinesis supports two different types of consumers - shared throughput consumers and enhanced fan-out consumers. In shared throughput, the shards in a stream provide 2 MB/sec of read throughput per shard. This throughput gets shared across all the consumers that are reading from a given shard. When a consumer uses enhanced fan-out, it gets its own 2 MB/sec allotment of read throughput, allowing multiple consumers to read data from the same stream in parallel, without contending for read throughput with other consumers. Databricks has supported Amazon Kinesis as a streaming source from DBR 3.0 onwards. This source uses the shared consumer model along with the support for resharding (merging and splitting shards). Several of our customers used this connector in multiple Structured Streaming jobs to consume events from a single large kinesis stream. This often becomes a bottleneck due to read throughput being exceeded, limiting the data processed and introducing inconsistent latency. Sometimes users would clone the kinesis stream to be used across multiple Structured Streaming jobs to get the full 2 MB/sec throughput which leads to operational overhead. To overcome this, we introduced the support for EFO mode in Databricks Kinesis connector. With this feature, users can choose the appropriate consumer mode depending on the required throughput, latency and cost. In addition to this, support forTrigger.AvailableNow has been added to the Kinesis source connector from DBR 13.1 and above. For more information, please read the documentation here. Availability - This feature has been available from DBR 11.3 and subsequent releases. For more details, read the blog - Announcing Support for Enhanced Fan-Out for Kinesis on Databricks. Google Pub/Sub is the primary streaming message bus offered by Google Cloud. In order to expand our Lakehouse platform and benefit our Structured Streaming customers in GCP, we decided to support Google Pub/Sub source connector natively. However, the Google Pub/Sub differs significantly from other message buses -  These differences posed challenges in developing the Pub/Sub connector as we wanted to have a uniform behavior similar to other Structured Streaming sources such as exactly once processing of the data, provide fault tolerance, and scale throughput linearly with the number of executors. We overcame these challenges by decoupling fetching from Pub/Sub from the microbatch execution. This allowed us to fetch data separately, handle any deduplication and create our own deterministic offsets on top of which we can build an exactly-once processing source. With the addition of Google Pub/Sub source connector, we now support all the streaming buses across the major cloud providers including Amazon Kinesis, Apache Kafka, and Azure EventHub (via Kafka interface).  Availability - This feature has been available from DBR 13.1 and subsequent releases. For more details, read the blog - Unlock the Power of Real-time Data Processing with Databricks and Google Cloud. In this blog, we provided an update on the Project Lightspeed that is advancing Apache Spark Structured Streaming across several dimensions - performance, functionality, observability and ecosystem expansion. We are still continuing to execute on Project Lightspeed and expect more announcements in the near future. See how our customers are operationalizing streaming data architectures with Spark Structured Streaming and the Databricks Lakehouse Platform here. See Careers\n",
      "at Databricks Databricks Inc.\n",
      "160 Spear Street, 13th Floor\n",
      "San Francisco, CA 94105\n",
      "1-866-330-0121 © Databricks 2023. All rights reserved. Apache, Apache Spark, Spark and the Spark logo are trademarks of the Apache Software Foundation.\n",
      "\n",
      "Created post for Introducing Lakehouse Federation Capabilities in Unity Catalog - https://www.databricks.com/blog/introducing-lakehouse-federation-capabilities-unity-catalog\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full text of Introducing Lakehouse Federation Capabilities in Unity Catalog: Discover how to build and manage all your data, analytics and AI use cases with the Databricks Lakehouse Platform Report\n",
      "\n",
      "Tap the potential of AI\n",
      "Explore recent findings from 600 CIOs across 14 industries in this MIT Technology Review report Missed Data + AI Summit?   Data + AI Summit is over, but you can still watch the keynotes and 250+ sessions from the event on demand. Connect with validated partner solutions in just a few clicks. See why Gartner named Databricks a Leader for the second consecutive year June 28, 2023 in Platform Blog Data teams face many challenges to quickly access the right data primarily due to data fragmentation, time and cost involved in consolidating data, and difficulties in managing data governance across many systems. That's why today at Data+AI Summit, we are thrilled to announce Lakehouse Federation capabilities in Unity Catalog that allow organizations to build a highly scalable and performant data mesh architecture with unified governance.  Unity Catalog provides a unified governance solution for data and AI. Lakehouse Federation capabilities in Unity Catalog allow you to discover, query, and govern data across data platforms including MySQL, PostgreSQL, Amazon Redshift, Snowflake, Azure SQL Database, Azure Synapse, Google’s BigQuery, and more from within Databricks without moving or copying the data, all within a simplified and unified experience. This means Unity Catalog's advanced security features such as row and column level access controls, discovery features like tags, and data lineage will be available across these external data sources, ensuring consistent governance. “Data scientists and business users alike can now access diverse data sources through a uniform user interface with consistent permissions managed in one place.\" said Jelle de Jong, Tech Lead at Bayer. \"We’re continuously standardizing our data format to Delta Lake, but we’re thrilled that Lakehouse Federation has allowed us to iterate with agility before investing in data extraction.” Thousands of organizations of all sizes are innovating across the world and all industries with data and AI on the Databricks Lakehouse Platform. But for historical, organizational or technological reasons, data is scattered across many operational and analytics systems, causing more challenges: Lakehouse Federation addresses these critical pain points and makes it simple for organizations to expose, query, and govern siloed data systems as an extension of their lakehouse. With these new capabilities, you can: “Lakehouse Federation gives us the ability to combine data — like usage, sales and game telemetry data — from multiple sources, across multiple clouds and view and query it all from one place. Now we leave the data in the original data source, but can utilize it from the Databricks Lakehouse.\" said Felix Baker, Head of Data Services at SEGA Europe. \"Since we no longer have to move our finance data, which is refreshed frequently, it saves us valuable time that can be focused on giving our consumers the best possible gaming experience.” \"Lakehouse Federation has enabled us to move more quickly to consolidate our existing data landscape into Unity Catalog. This makes Shell's data governance simpler – more datasets become discoverable in one place, authentication is standardized and querying across datasets with a common programming language becomes possible,\" said Bryce Bartmann, Chief Digital Technology Advisor at Shell. \"Ultimately, it makes us more effective in navigating the transformation happening in the energy sector today.\" These new capabilities coupled with the recently announced open Hive interface mean that organizations can centralize their data management, discovery, and governance in Unity Catalog, and connect to it from a wide range of computing platforms, including Amazon EMR, Apache Spark, Amazon Athena, Presto, Trino, and others. The new interface eliminates the need for maintaining multiple data catalogs and ensures consistent data governance across these platforms. These new capabilities are currently in private preview. You can sign up here for our public preview coming in July.  We are also extending Unity Catalog’s governance capabilities to various open storage formats including Apache Iceberg and Hudi, with the public preview of the Delta Universal Format (\"UniForm\"). This integration allows Delta tables to be read as if they were Iceberg tables (and soon Apache Hudi as well), making Unity Catalog the only universal catalog that supports all three major open lakehouse storage formats. Finally, in the future, you will also be able to push access policies defined in Unity Catalog, to federated data sources for consistent enforcement wherever data is accessed. This eliminates the need to maintain redundant policy definitions across different governance tools. Watch the Data+AI Summit 2023 keynote from Matei Zaharia, co-founder and Chief Technology Officer at Databricks, to learn more. Register for the Data + AI Summit here to join us in person or virtually and explore the latest in data, analytics, and AI! See Careers\n",
      "at Databricks Databricks Inc.\n",
      "160 Spear Street, 13th Floor\n",
      "San Francisco, CA 94105\n",
      "1-866-330-0121 © Databricks 2023. All rights reserved. Apache, Apache Spark, Spark and the Spark logo are trademarks of the Apache Software Foundation.\n",
      "\n",
      "Created post for Introducing Materialized Views and Streaming Tables for Databricks SQL - https://www.databricks.com/blog/introducing-materialized-views-and-streaming-tables-databricks-sql\n",
      "Full text of Introducing Materialized Views and Streaming Tables for Databricks SQL: Discover how to build and manage all your data, analytics and AI use cases with the Databricks Lakehouse Platform Report\n",
      "\n",
      "Tap the potential of AI\n",
      "Explore recent findings from 600 CIOs across 14 industries in this MIT Technology Review report Missed Data + AI Summit?   Data + AI Summit is over, but you can still watch the keynotes and 250+ sessions from the event on demand. Connect with validated partner solutions in just a few clicks. See why Gartner named Databricks a Leader for the second consecutive year June 28, 2023 in Platform Blog We are thrilled to announce that materialized views and streaming tables are now publicly available in Databricks SQL on AWS and Azure. Streaming tables provide incremental ingest from cloud storage and message queues. Materialized views are automatically and incrementally updated as new data arrives. Together, these two capabilities enable infrastructure-free data pipelines that are simple to set up and deliver fresh data to the business. In this blog post, we will explore how these new capabilities empower analysts and analytics engineers to deliver data and analytics applications more effectively in the data warehouse. Data warehousing and data engineering are crucial for any data-driven organization. Data warehouses serve as the primary location for analytics and reporting, while data engineering involves creating data pipelines to ingest and transform data. However, traditional data warehouses are not designed for streaming ingestion and transformation. Ingesting large volumes of data with low latency in a traditional data warehouse is expensive and complex because legacy data warehouses were designed for batch processing. As a result, teams have had to implement clumsy solutions that required configurations outside of the warehouse and needed to use cloud storage as an intermediate staging location. Managing these systems is costly, prone to errors, and complex to maintain. The Databricks Lakehouse Platform disrupts this traditional paradigm by providing a unified solution. Delta Live Tables (DLT) is the best place to do data engineering and streaming, and Databricks SQL provides up to 12x better price/performance for analytics workloads on existing data lakes. Additionally, now partners like dbt can integrate with these native capabilities which we describe in more detail later in this announcement. Data warehouses serve as the primary location for analytics and data delivery for internal reporting through business intelligence (BI) applications. Organizations face several challenges in adopting data warehouses: Streaming tables and materialized views empower SQL analysts with data engineering best practices. Consider an example of continuously ingesting newly arrived files from an S3 location and preparing a simple reporting table. With Databricks SQL the analyst can quickly discover and preview the files in S3 and set up a simple ETL pipeline in minutes, using only a few lines of code as in the following example: 1- Discover and preview data in S3 2- Ingest data in a streaming fashion 3- Aggregate data incrementally using a materialized view Materialized views reduce cost and improve query latency by pre-computing slow queries and frequently used computations. In a data engineering context, they are used for transforming data. But they are also valuable for analyst teams in a data warehousing context because they can be used to (1) speed up end-user queries and BI dashboards, and (2) securely share data. Built on top of Delta Live Tables, MVs reduce query latency by pre-computing otherwise slow queries and frequently used computations.  Benefits of materialized views: Ingestion in DBSQL is accomplished with streaming tables (STs). You can think of STs as ideal for bringing data into “bronze” tables. STs enable continuous, scalable ingestion from any data source including cloud storage, message buses (EventHub, Apache Kafka) and more.  Benefits of streaming tables:  Databricks SQL empowers SQL and data analysts to easily ingest, clean, and enrich data to meet the needs of the business without relying on third-party tools. Everything can be done entirely in SQL, streamlining the workflow. By leveraging materialized views and streaming tables, you can:  Adobe has an advanced approach to AI, with a mission of making the world more creative, productive, and personalized with artificial intelligence as a co-pilot that amplifies human ingenuity. As a leading preview customer of Materialized Views on Databricks SQL, they have seen enormous technical and business benefits that help them deliver on this mission:  Founded in 1948, Danske Spil is Denmark’s national lottery and was one of our early preview customers for DB SQL Materialized Views. Søren Klein, Data Engineering Team Lead, shares his perspective on what makes Materialized Views so valuable for the organization: Databricks and dbt Labs collaborate to simplify real-time analytics engineering on the lakehouse architecture. The combination of dbt's highly popular analytics engineering framework with the Databricks Lakehouse Platform provides powerful capabilities: Data warehousing and data engineering are critical components of any data-driven company. However, managing separate solutions for each aspect is costly, error-prone, and challenging to maintain. The Databricks Lakehouse Platform brings the best data engineering capabilities natively into Databricks SQL, empowering SQL users with a unified solution. Additionally, our integration with partners like dbt empowers our joint customers to leverage these unique capabilities to deliver faster insights, real-time analytics, and streamlined data engineering workflows. Get access to Databricks SQL materialized views and streaming tables by following this link. You can also get started today with Databricks and Databricks SQL, or review the documentation for materialized views and streaming tables. See Careers\n",
      "at Databricks Databricks Inc.\n",
      "160 Spear Street, 13th Floor\n",
      "San Francisco, CA 94105\n",
      "1-866-330-0121 © Databricks 2023. All rights reserved. Apache, Apache Spark, Spark and the Spark logo are trademarks of the Apache Software Foundation.\n",
      "\n",
      "Created post for A guide to Databricks SQL and Data Warehousing talks at Data + AI Summit 2023 - https://www.databricks.com/blog/guide-databricks-sql-and-data-warehousing-talks-data-ai-summit-2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full text of A guide to Databricks SQL and Data Warehousing talks at Data + AI Summit 2023: Discover how to build and manage all your data, analytics and AI use cases with the Databricks Lakehouse Platform Report\n",
      "\n",
      "Tap the potential of AI\n",
      "Explore recent findings from 600 CIOs across 14 industries in this MIT Technology Review report Missed Data + AI Summit?   Data + AI Summit is over, but you can still watch the keynotes and 250+ sessions from the event on demand. Connect with validated partner solutions in just a few clicks. See why Gartner named Databricks a Leader for the second consecutive year June 14, 2023 in Engineering Blog It's been only 18 months since we announced Databricks SQL general availability - the serverless data warehouse on the Lakehouse - and we are thrilled and humbled by the adoption and impact it has gained in the community. With thousands of customers worldwide, and already over $100 million in recurring revenue, Databricks SQL is one of the fastest growing product at Databricks, confirming that the best data warehouse is a lakehouse! To learn more, simply watch our most recent virtual event The Case for Moving to the Lakehouse co-presented with Fivetran and dbt, and we will have much more coming at Data + AI Summit. Below is a list of related sessions, tutorials, and trainings for you to dive in. Join us on Wednesday, June 28, where we will be announcing new capabilities related to Generative AI, data and AI governance, and Databricks SQL. To give you a sneak peak, we will cover how we are radically rethinking the system building to achieve the next level performance and ease-of-use with AI on the Lakehouse. We also have a fantastic lineup of speakers and sessions throughout the conference. Join experts from Akamai, AT&T, Michelin, Banco Bradesco, Intel, Apple, Microsoft, Amazon Web Services, Fivetran, MongoDB, Databricks and more for real-life examples and deep dives on Databricks SQL and Data Warehousing on the Lakehouse.   Customer Talks Community Talks Databricks Talks Free Tutorial Trainings You can browse through our entire sessions catalog from Data + AI Summit 2023 too! Top experts, researchers and open source contributors from Databricks and across the data and AI community will speak at Data + AI Summit, so you will be in good company! Join us at Data + AI Summit 2023 to learn more. See Careers\n",
      "at Databricks Databricks Inc.\n",
      "160 Spear Street, 13th Floor\n",
      "San Francisco, CA 94105\n",
      "1-866-330-0121 © Databricks 2023. All rights reserved. Apache, Apache Spark, Spark and the Spark logo are trademarks of the Apache Software Foundation.\n",
      "\n",
      "Created post for Seamlessly Migrate Your Apache Parquet Data Lake to Delta Lake - https://www.databricks.com/blog/seamlessly-migrate-your-apache-parquet-data-lake-delta-lake\n",
      "Full text of Seamlessly Migrate Your Apache Parquet Data Lake to Delta Lake: Discover how to build and manage all your data, analytics and AI use cases with the Databricks Lakehouse Platform Report\n",
      "\n",
      "Tap the potential of AI\n",
      "Explore recent findings from 600 CIOs across 14 industries in this MIT Technology Review report Missed Data + AI Summit?   Data + AI Summit is over, but you can still watch the keynotes and 250+ sessions from the event on demand. Connect with validated partner solutions in just a few clicks. See why Gartner named Databricks a Leader for the second consecutive year June 6, 2023 in Engineering Blog Apache Parquet is one of the most popular open source file formats in the big data world today. Being column-oriented, Apache Parquet allows for efficient data storage and retrieval, and this has led many organizations over the past decade to adopt it as an essential way to store data in data lakes. Some of these companies went one step further and decided to use Apache Parquet files as 'database tables' – performing CRUD operations on them. However, Apache Parquet files, being just data files, without any transaction logging, statistics collection and indexing capabilities aren't good candidates for ACID compliant database operations. Building such tooling is a monumental task that would require a huge development team to develop on their own and to maintain it. The result was an Apache Parquet Data Lake. It was a makeshift solution at its best, suffering from issues such as accidental corruption of tables arising from brittle ACID compliance. The solution came in the form of the Delta Lake format. It was designed to solve the exact problems Apache Parquet data lakes were riddled with. Apache Parquet was adopted as the base data storage format for Delta Lake and the missing transaction logging, statistics collection and indexing capabilities were built in, providing it with the much needed ACID compliance and guarantees. Open source Delta Lake, under the Linux Foundation, has been going from strength to strength, finding wide usage in the industry. Over time, organizations have realized significant benefits moving their Apache Parquet data lake to Delta Lake, but it takes planning and selection of the right approach to migrate the data. There can even be scenarios where a business needs the Apache Parquet Data Lake to co-exist even after migrating the data to Delta Lake. For example, you might have an ETL pipeline that writes data to tables stored in Apache Parquet Data lake and you need to perform a detailed impact analysis before gradually migrating the data to Delta Lake. Until such time, you need to keep their Apache Parquet Data Lake and Delta Lake in sync. In this blog we will discuss a few similar use cases and show you how to tackle them. You can refer to this Databricks Blog series to understand Delta Lake internal functionality. The methodology that needs to be adopted for the migration of Apache Parquet Data Lake to Delta Lake depends on one or many migration requirements which are documented in the matrix below. Table 1 - Matrix to show options for migrations Now let's discuss the migration requirements and how that impacts the choice of migration methodologies. You can use Databricks deep clone functionality to incrementally convert data from the Apache Parquet Data lake to the Delta Lake. Use this approach when all of the below criteria are satisfied: You can use Databricks shallow clone functionality to incrementally convert data from Apache Parquet Data lake to Delta Lake, when you: You can use Convert to Delta Lake feature if you have requirements for: Since the source is transformed into a target Delta Lake table in-place, all future CRUD operations on the target table need to happen through Delta Lake ACID transactions. Note - Please refer to the Caveats before using the CONVERT TO DELTA option. You should avoid updating or appending data files during the conversion process. After the table is converted, make sure all writes go through Delta Lake. You can use Auto Loader to incrementally copy all data from a given cloud storage directory to a target Delta table. This approach can be used for the below conditions: You can use COPY INTO SQL command to incrementally copy all data from a given cloud storage directory to a target Delta table. This approach can be used for the below conditions: Both Auto Loader and COPY INTO allow the users plenty of options to configure the data movement process. Refer to this link when you need to decide between COPY INTO and Auto Loader.  Finally, you can use custom Apache Spark logic to migrate to Delta Lake. It provides great flexibility in controlling how and when different data from your source system is migrated, but might require extensive configuration and customization to provide capabilities already built into the other methodologies discussed here. To perform backfills or incremental migration, you might be able to rely on the partitioning structure of your data source, but might also need to write custom logic to track which files have been added since you last loaded data from the source. While you can use Delta Lake merge capabilities to avoid writing duplicate records, comparing all records from a large Parquet source table to the contents of a large Delta table is a complex and computationally expensive task. Refer to this link for more information on the methodologies of migrating your Apache Parquet Data Lake to Delta Lake. In this blog, we have described various options to migrate your Apache Parquet Data Lake to Delta Lake and discussed how you can determine the right methodology based on your requirements. To learn more about the Apache Parquet to Delta Lake migration and how to get started, please visit the guides (AWS, Azure, GCP). In these Notebooks we have provided a few examples for you to get started and try different options for migration. Also it is always recommended to follow optimization best practices on Databricks after you migrate to Delta Lake. See Careers\n",
      "at Databricks Databricks Inc.\n",
      "160 Spear Street, 13th Floor\n",
      "San Francisco, CA 94105\n",
      "1-866-330-0121 © Databricks 2023. All rights reserved. Apache, Apache Spark, Spark and the Spark logo are trademarks of the Apache Software Foundation.\n",
      "\n",
      "Created post for Adaptive Query Execution in Structured Streaming - https://www.databricks.com/blog/adaptive-query-execution-structured-streaming\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full text of Adaptive Query Execution in Structured Streaming: Discover how to build and manage all your data, analytics and AI use cases with the Databricks Lakehouse Platform Report\n",
      "\n",
      "Tap the potential of AI\n",
      "Explore recent findings from 600 CIOs across 14 industries in this MIT Technology Review report Missed Data + AI Summit?   Data + AI Summit is over, but you can still watch the keynotes and 250+ sessions from the event on demand. Connect with validated partner solutions in just a few clicks. See why Gartner named Databricks a Leader for the second consecutive year June 2, 2023 in Engineering Blog In Databricks Runtime, Adaptive Query Execution (AQE) is a performance feature that continuously re-optimizes batch queries using runtime statistics during query execution. Starting from Databricks Runtime 13.1, real-time streaming queries that use the ForeachBatch Sink will also leverage AQE for dynamic re-optimizations as part of Project Lightspeed. At Databricks, Structured Streaming handles petabytes of real-time data daily. The ForeachBatch streaming sink, used by over 40% of customers, often incorporates the most resource-intensive operations, such as joins and Delta MERGE with large volumes of data. The resulting multi-staged execution plans have the most potential to be re-optimized by AQE. Streaming queries have relied on static query planning and estimated statistics, leading to several known issues previously seen in batch queries, including poor physical strategy decisions and skewed data distributions that degrade performance. To address those challenges, we exploit the runtime statistics collected during the micro-batch execution of the ForeachBatch Sink for dynamic optimizations. Adaptive query replanning will be triggered independently on each micro-batch because the characteristics of the data may change over time across different micro-batches. The effect of AQE is isolated on stateless operators and is applied to the micro-batch DataFrame within the ForeachBatch callable function. Operators directly applied to the streaming DataFrame before invoking ForeachBatch are executed in a different query plan without AQE because those operators could be stateful. Separation of execution prevents AQE repartitioning on stateful operators, which can take away locality and cause correctness issues. For Photon-enabled clusters, each micro-batch from a stateless query is executed with a cohesive query plan practically identical to that of a batch Photon query. This design allows the widest range of logical and physical optimizations. AQE will take effect for most stateless Photon-enabled queries using the ForeachBatch Sink. Generally, AQE will be most effective when transformations can be applied within the ForeachBatch Sink. The sample code below shows two semantically identical streaming queries. The second query is recommended for potentially better AQE coverage since the join is moved inside the ForeachBatch function. Consider a simplified example of a streaming Delta MERGE query which is used for upserting real-time data into a Delta table: Scanning for matches is often the most costly part of a Delta Merge query. Let’s examine the Spark UI snippets of a query plan that executes the matching process on a sample micro-batch. First, AQE Plan Versions contain links that show how the plan evolved during execution. The AdaptiveSparkPlan root node indicates that AQE was applied to this query plan because it contained at least one shuffle.  The snippet below shows that AQE applied dynamic coalescing of small partitions in this particular example.  Comparing plan versions in this example also shows that AQE dynamically switched from a SortMergeJoin to a BroadcastHashJoin, which can significantly speed up the join.  As shown below, one of the leaf nodes of the query plan is an RDD Scan which reads the materialized micro-batch data from the streaming subplan which may contain stateful operators.  If the same query was executed in Photon, instead of an RDD Scan, the execution plan would incorporate all downstream operators, including the data stream source. Leveraging AQE, stateless benchmark queries bottlenecked by expensive joins and aggregations typically experienced a speedup ranging from 1.2x to 2x, with one query that had particularly poor static planning experiencing a 16x speedup. Partition size re-optimizations and dynamic join strategy selections were observed in the speedup queries. As expected, AQE did not impact the performance for stateful queries and queries with few transformations. The additional dynamic filters enabled by AQE and join re-optimizations can be particularly effective with Delta MERGE, which is a common streaming use case. As shown in the chart below, internal benchmarks demonstrated a median 1.38x speedup with just AQE and 2.87x speedup if AQE is enabled along with the Photon engine.  AQE in streaming will be enabled by default in Runtime 13.1 for non-Photon clusters and in Runtime 13.2 for Photon clusters. With AQE in ForeachBatch, customers can now benefit from the same dynamic optimizations used in batch queries for their streaming workloads. Also, look forward to the coming improvements to AQE, including Adaptive Join Fallback and other AI-powered features enabled by AQE. See Careers\n",
      "at Databricks Databricks Inc.\n",
      "160 Spear Street, 13th Floor\n",
      "San Francisco, CA 94105\n",
      "1-866-330-0121 © Databricks 2023. All rights reserved. Apache, Apache Spark, Spark and the Spark logo are trademarks of the Apache Software Foundation.\n",
      "\n",
      "Created post for Announcing the General Availability of Databricks SQL Serverless ! - https://www.databricks.com/blog/announcing-general-availability-databricks-sql-serverless\n",
      "Full text of Announcing the General Availability of Databricks SQL Serverless !: Discover how to build and manage all your data, analytics and AI use cases with the Databricks Lakehouse Platform Report\n",
      "\n",
      "Tap the potential of AI\n",
      "Explore recent findings from 600 CIOs across 14 industries in this MIT Technology Review report Missed Data + AI Summit?   Data + AI Summit is over, but you can still watch the keynotes and 250+ sessions from the event on demand. Connect with validated partner solutions in just a few clicks. See why Gartner named Databricks a Leader for the second consecutive year May 18, 2023 in Platform Blog Today, we are thrilled to announce that serverless compute for Databricks SQL is Generally Available on AWS and Azure! Databricks SQL (DB SQL) Serverless provides the best performance with instant and elastic compute, lowers costs, and enables you to focus on delivering the most value to your business rather than managing infrastructure. With GA, you can expect the highest level of stability, support and enterprise-readiness from Databricks for mission-critical workloads on the Databricks Lakehouse Platform. In this blog post, we will review the benefits of DB SQL Serverless and discuss some of the latest features released to provide you with world-class data warehousing performance. Over the last couple of years, we've seen tremendous growth and adoption of Databricks SQL - our data warehouse purpose-built for the Lakehouse. DB SQL is helping leading companies like Akamai, T-Mobile, and CRED drive innovation by powering modern analytics use cases around the globe - at any scale. From startups to enterprises, thousands of companies are using Databricks SQL to power the next generation of self-service analytics and data applications, and serverless makes their experience even better with instant, elastic compute, lower infrastructure costs, and no management overhead. It's been an incredible journey so far. As we always thrive to provide you with the best experiences, we built Databricks SQL serverless so you can benefit from: In addition to all the infrastructure improvements mentioned above, DB SQL Serverless is also packed with performance and cost optimizations features for all analytics use cases: Did you know that you can benefit today from a price reduction on Databricks SQL Serverless? Visit our pricing page for more information and watch our latest virtual event The Case for Moving to the Lakehouse co-presented with Fivetran and dbt to learn more about our Data Warehouse offering, including Databricks SQL Serverless and Unity Catalog. If you are already a Databricks customer, simply follow the guide to get started on AWS or Azure. As a reminder, Databricks SQL Serverless is now supported on AWS in the following regions: and on Azure in the following regions, and more coming soon. Join us at Data + AI Summit 2023 to learn more. See Careers\n",
      "at Databricks Databricks Inc.\n",
      "160 Spear Street, 13th Floor\n",
      "San Francisco, CA 94105\n",
      "1-866-330-0121 © Databricks 2023. All rights reserved. Apache, Apache Spark, Spark and the Spark logo are trademarks of the Apache Software Foundation.\n",
      "\n",
      "Created post for Latency goes subsecond in Apache Spark Structured Streaming - https://www.databricks.com/blog/latency-goes-subsecond-apache-spark-structured-streaming\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full text of Latency goes subsecond in Apache Spark Structured Streaming: Discover how to build and manage all your data, analytics and AI use cases with the Databricks Lakehouse Platform Report\n",
      "\n",
      "Tap the potential of AI\n",
      "Explore recent findings from 600 CIOs across 14 industries in this MIT Technology Review report Missed Data + AI Summit?   Data + AI Summit is over, but you can still watch the keynotes and 250+ sessions from the event on demand. Connect with validated partner solutions in just a few clicks. See why Gartner named Databricks a Leader for the second consecutive year May 15, 2023 in Engineering Blog Apache Spark Structured Streaming is the leading open source stream processing platform. It is also the core technology that powers streaming on the Databricks Lakehouse Platform and provides a unified API for batch and stream processing. As the adoption of streaming is growing rapidly, diverse applications want to take advantage of it for real time decision making. Some of these applications, especially those operational in nature, demand lower latency. While Spark's design enables high throughput and ease-of-use at a lower cost, it has not been optimized for sub-second latency. In this blog, we will focus on the improvements we have made around offset management to lower the inherent processing latency of Structured Streaming. These improvements primarily target operational use cases such as real time monitoring and alerting that are simple and stateless. Extensive evaluation of these enhancements indicates that the latency has improved by 68-75% - or as much as 3X - from 700-900 ms to 150-250 ms for throughputs of 100K events/sec, 500K events/sec and 1M events/sec. Structured Streaming can now achieve latencies lower than 250 ms, satisfying SLA requirements for a large percentage of operational workloads. This article assumes that the reader has a basic understanding of Spark Structured Streaming. Refer to the following documentation to learn more: https://www.databricks.com/spark/getting-started-with-apache-spark/streaminghttps://docs.databricks.com/structured-streaming/index.htmlhttps://www.databricks.com/glossary/what-is-structured-streaminghttps://spark.apache.org/docs/latest/structured-streaming-programming-guide.html Apache Spark Structured Streaming is a distributed stream processing engine built on top of the Apache Spark SQL engine. It provides an API that allows developers to process data streams by writing streaming queries in the same way as batch queries, making it easier to reason about and test streaming applications. According to Maven downloads, Structured Streaming is the most widely used open source distributed streaming engine today. One of the main reasons for its popularity is performance - high throughput at a lower cost with an end-to-end latency under a few seconds. Structured Streaming gives users the flexibility to balance the tradeoff between throughput, cost and latency. As the adoption of streaming grows rapidly in the enterprise, there is a desire to enable a diverse set of applications to use streaming data architecture. In our conversations with many customers, we have encountered use cases that require consistent sub-second latency. Such low latency use cases arise from applications like operational alerting and real time monitoring, a.k.a \"operational workloads.\" In order to accommodate these workloads into Structured Streaming, in 2022 we launched a performance improvement initiative under Project Lightspeed. This initiative identified potential areas and techniques that can be used to improve processing latency. In this blog, we outline one such area for improvement in detail - offset management for progress tracking and how it achieves sub-second latency for operational workloads. Streaming workloads can be broadly categorized into analytical workloads and operational workloads. Figure 1 illustrates both analytical and operational workloads. Analytical workloads typically ingest, transform, process and analyze data in real time and write the results into Delta Lake backed by object storage like AWS S3, Azure Data Lake Gen2 and Google Cloud Storage. These results are consumed by downstream data warehousing engines and visualization tools. Figure 1. Analytical vs Operational Workloads Some examples of analytical workloads include: On the other hand, operational workloads, ingest and process data in real time and automatically trigger a business process. Some examples of such workloads include: Operational streaming pipelines share the following characteristics: For these use cases, when we profiled Structured Streaming, we identified that the offset management to track the progress of micro-batches consumes substantial time. In the next section, let us review the existing offset management and outline how we improved in subsequent sections. To track the progress of up to which point the data has been processed, Spark Structured Streaming relies on persisting and managing offsets which are used as progress indicators. Typically, an offset is concretely defined by the source connector as different systems have different ways to represent progress or locations in data. For example, a concrete implementation of an offset can be the line number in a file to indicate how far the data in the file has been processed. Durable logs (as depicted in Figure 2) are used to store these offset and mark completion of micro-batches. In Structured Streaming, data is processed in units of micro-batches. There are two offset management operations done for each micro-batch. One at the beginning of every micro-batch and one at the end. Figure 3 below depicts the current offset management operations that occur. Another offset management operation is performed at the end of every micro-batch. This operation is a clean up operation to delete / truncate old and unnecessary entries from both the offsetLog and commitLog so that these logs don't grow in an unbounded fashion. These offset management operations are performed on the critical path and inline with the actual processing of the data. This means that the duration of these operations directly impacts processing latency and no data processing can occur until these operations are complete. This directly impacts cluster utilization as well. Through our benchmarking and performance profiling efforts, we have identified these offset management operations can take up a majority of the processing time especially for stateless single state pipelines that are often used in the operation alerting and real-time monitoring use cases. This feature was created to address the latency overhead of persisting offsets for progress tracking purposes. This feature, when enabled, will allow Structured Streaming pipelines to checkpoint progress, i.e. update the offsetLog and commitLog, asynchronously and in parallel to the actual data processing within a micro-batch. In other words, the actual data processing will not be blocked by these offset management operations which will significantly improve the latency of applications. Figure 5 below depicts this new behavior for offset management. In conjunction with asynchronously performing updates, users can configure the frequency at which the progress is checkpointed. This will be helpful for scenarios in which offset management operations occur at a higher rate than they can be processed. This happens in pipelines when the time spent actually processing data is significantly less compared to these offset management operations. In such scenarios, an ever increasing backlog of offset management operations will occur. To stem this growing backlog, data processing will have to be blocked or slowed down which will essentially revert the processing behavior to being the same as if these offset management operations were executed inline with the data processing. A user will typically not need to configure or set the checkpoint frequency as an adequate default value will be set. It is important to note that failure recovery time will increase with the increase in checkpoint interval time. In case of failure, a pipeline has to reprocess all the data before the previous successful checkpoint. Users can consider this trade-off between lower latency during regular processing and recovery time in case of failure. Following configurations are introduced to enable and configure this feature: Following code sample illustrates how to enable this feature: Note that this feature will not work with Trigger.once or Trigger.availableNow as these triggers execute pipelines in manual/scheduled fashion. Therefore, asynchronous progress tracking will not be relevant. Query will fail if it is submitted using any of the aforementioned triggers. There are a couple of limitations in the current version(s) that might change as we evolve the feature: This feature was created to address the latency overhead of the log cleanups that were done in line within a micro-batch. By making this log cleanup/purge operation asynchronous and performed in the background, we can remove the latency overhead this operation will incur on actual data processing. Also, these purges do not need to be done with every micro-batch and can occur on a more relaxed schedule. Note that this feature / improvement does not have any limitations on what type of pipelines or workloads can use this, thus this feature will be enabled in the background by default for all Structured Streaming pipelines. In order to understand the performance of async progress tracking and async log purging, we created a few benchmarks. Our goal with the benchmarks is to understand the difference in performance that the improved offset management provides in an end-to-end streaming pipeline. The benchmarks are divided into two categories: For both these benchmarks, we measured the end to end latency (50th percentile, 99th percentile) at different data input rates (100K events/sec, 500K events/sec, 1M events/sec). The main methodology was to generate data from a source at a particular constant throughput. The generated records contain information about when the records were created. On the sink side, we use the Apache DataSketches library to collect the difference between the time the sink processes the record and the time that it was created in each batch. This is used to calculate the latency. We used the same cluster with the same number of nodes for all experiments. Note: For the Kafka benchmark, we put aside some nodes of a cluster for running Kafka and generating the data for feeding to Kafka. We calculate the latency of a record only after the record has been successfully published into Kafka (on the sink) For this benchmark, we used a Spark cluster of 7 worker nodes (i3.2xlarge - 4 cores, 61 GiB memory) using the Databricks runtime (11.3). We measured the end to end latency for the following scenarios to quantify the contribution of each improvement. The results of these experiments are shown in Figures 6, 7 and 8. As you can see, async log purging consistently reduces the latency approximately by 50%. Similarly, async progress tracking alone improves latency by approximately 65%. Combined together, the latency reduces by 85-86% and the latency goes below 100 ms. For the Kafka benchmarks, we used a Spark cluster of 5 worker nodes (i3.2xlarge - 4 cores, 61 GiB memory), a separate cluster of 3 nodes to run Kafka and an additional 2 nodes to generate data added to the Kafka source. Our Kafka topic has 40 partitions and a replication factor of 3. The data generator publishes the data into a Kafka topic and the structured streaming pipeline consumes data and republishes into another Kafka topic. The results of the performance evaluation are shown in Figures 9, 10 and 11. As one can see, after applying async progress and async log purging, the latency reduces by 65-75% or 3-3.5X across different throughputs. With the new asynchronous progress tracking and asynchronous log purge, we can see that both configs reduce latency as much as 3X. Working together, latency is greatly reduced across all throughputs. The charts also show that the amount of time saved is usually a constant amount of time (200 - 250 ms for each config) and together they can shave off around 500 ms across the board (leaving enough time for batch planning and query processing). These performance improvements are available in Databricks Lakehouse Platform from DBR 11.3 onwards. Async log purging is enabled by default in DBR 11.3 and subsequent releases. Furthermore, these improvements have been contributed to Open Source Spark and is available from Apache Spark 3.4 onwards. There are currently some limitations to the types of workloads and sinks supported by the asynchronous progress tracking feature. We will be looking into supporting more types of workloads with this feature in the future. This is only the beginning of the predictable low latency features we are building in Structured Streaming as part of Project Lightspeed. In addition, we will continue to benchmark and profile Structured Streaming to find more areas of improvement. Stay tuned! Join us at the Data and AI Summit in San Francisco, June 26-29 to learn more about Project Lightspeed and data streaming on the Databricks Lakehouse Platform. See Careers\n",
      "at Databricks Databricks Inc.\n",
      "160 Spear Street, 13th Floor\n",
      "San Francisco, CA 94105\n",
      "1-866-330-0121 © Databricks 2023. All rights reserved. Apache, Apache Spark, Spark and the Spark logo are trademarks of the Apache Software Foundation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "import requests\n",
    "\n",
    "url = 'http://www.databricks.com/blog/category/engineering/feed'\n",
    "feed = feedparser.parse(url)\n",
    "\n",
    "print(feed.entries[0])\n",
    "for entry in feed.entries:\n",
    "    \n",
    "    # Fetch title and description\n",
    "    title = entry.title\n",
    "    description = getattr(entry, \"description\", \"\")\n",
    "    link = entry.link\n",
    "    # Convert the timestamp into yyyy-mm-dd format\n",
    "    published_at = parse_date(entry.published)\n",
    "    link = entry.link\n",
    "    print(f\"Created post for {title} - {link}\")\n",
    "    \n",
    "    # Get the full text of the blog post\n",
    "    full_text = get_full_text(link)\n",
    "    print(f\"Full text of {title}: {full_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a7a3bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def parse_date(date_string):\n",
    "    formats = [\n",
    "        \"%Y-%m-%dT%H:%M:%SZ\",  # Format like '2023-07-06T19:00:51Z'\n",
    "        \"%a, %d %b %Y %H:%M:%S %Z\",  # Format like 'Tue, 20 Jun 2023 00:00:00 GMT'\n",
    "        \"%a, %d %b %Y %H:%M:%S %z\",  # Format like 'Wed, 08 Mar 2023 00:00:00 +0000'\n",
    "        \"%Y-%m-%dT%H:%M:%S.%f%z\",  # Format like '2023-07-06T12:50:00.000-07:00'\n",
    "        \"%Y-%m-%d %H:%M:%S\",  # Format like '2023-06-29 16:30:00'\n",
    "    ]\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(date_string, fmt).strftime(\"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            continue\n",
    "    raise ValueError(f\"couldn't parse date {date_string} with any of the known formats\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a53436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_full_text(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Assuming that the blog post text is within <p> tags\n",
    "    text = ' '.join([p.text for p in soup.find_all('p')])\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5f1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
